{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(input_str):   \n",
    "    return re.findall(r'\\w+', input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token = namedtuple('Token', 'token style raw_tokens label start end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# available for python > 3.5\n",
    "from typing import List, NamedTuple\n",
    "from functools import partial\n",
    "\n",
    "class AnnotationResult(NamedTuple):\n",
    "    span: tuple\n",
    "    text: str\n",
    "    label: str\n",
    "        \n",
    "class Token(NamedTuple):\n",
    "    token: str\n",
    "    style: str # https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Styling.html#Predefined-styles\n",
    "    raw_tokens: list # [str]\n",
    "    label: str\n",
    "    start: int\n",
    "    end: int\n",
    "    \n",
    "    @staticmethod\n",
    "    def merge(token1, token2):\n",
    "        return Token(\n",
    "            token=token1.token + ' ' + token2.token,\n",
    "            style=token1.style or token2.style,\n",
    "            raw_tokens = token1.raw_tokens + token2.raw_tokens,\n",
    "            label=token1.label or token2.label,\n",
    "            start=min(token1.start,token2.start),\n",
    "            end=max(token1.end, token2.end))\n",
    "\n",
    "    @staticmethod\n",
    "    def merge_all(tokens):\n",
    "        while len(tokens) > 1:\n",
    "            tokens = [Token.merge(tokens[0], tokens[1])] + tokens[2:]\n",
    "        return tokens[0]\n",
    "        \n",
    "\n",
    "class Annotator:\n",
    "    \n",
    "    LINE_MAX_WIDTH = 50\n",
    "    \n",
    "    def __init__(self, docs, scheme):\n",
    "        self.mapping = self._create_style_mapping(scheme)\n",
    "        self.raw_docs = docs\n",
    "        self.docs = [self._internal_doc(doc) for doc in docs]\n",
    "        assert len(docs) > 0, 'Should pass at least 1 text to annotate'\n",
    "        self.current_index = 0\n",
    "        self.render()\n",
    "    \n",
    "    @classmethod\n",
    "    def _internal_doc(cls, from_text):\n",
    "        original_tokens = cls._tokenize(from_text)\n",
    "        from_index = 0\n",
    "        doc = []\n",
    "        for token in original_tokens:\n",
    "            start = from_text.find(token, from_index)\n",
    "            from_index = start + len(token)\n",
    "            doc.append(Token(\n",
    "                token=token,\n",
    "                style='',\n",
    "                raw_tokens=[token],\n",
    "                start=start,\n",
    "                end=start + len(token),\n",
    "                label=None\n",
    "            ))\n",
    "        return doc\n",
    "    \n",
    "    def _on_label(self, doc, new_label, _):\n",
    "        new_merged = []\n",
    "        stack = []\n",
    "        for token, check in zip(doc, self.span_check_togglers):\n",
    "            if check.value:\n",
    "                new_token = token._replace(label=new_label, style=self.mapping[new_label])\n",
    "                stack.append(new_token)\n",
    "            else:\n",
    "                if len(stack):\n",
    "                    new_merged.append(Token.merge_all(stack))\n",
    "                    stack = []\n",
    "                new_merged.append(token)\n",
    "        if len(stack):\n",
    "            new_merged.append(Token.merge_all(stack))\n",
    "        doc[:] = new_merged\n",
    "        self.render()\n",
    "    \n",
    "    def _generate_labelling_for(self, doc):\n",
    "        self.span_check_togglers = []\n",
    "\n",
    "        for merged_token in doc:\n",
    "            self.span_check_togglers.append(widgets.ToggleButton(\n",
    "                value=False,\n",
    "                description=merged_token.token,\n",
    "                button_style=merged_token.style,\n",
    "                disabled=False,\n",
    "                tooltip='Click to select for merging + assigning class'\n",
    "            ))\n",
    "        \n",
    "        label_buttons = []\n",
    "        for label, button_style in self.mapping.items():\n",
    "            label_button = widgets.Button(description=f'Merge as {label}', button_style=button_style, icon='check')\n",
    "            label_button.on_click(partial(self._on_label, doc, label))\n",
    "            label_buttons.append(label_button)\n",
    "        \n",
    "        rows = self._break_into_rows(self.span_check_togglers)\n",
    "        labelling_widget = widgets.VBox([\n",
    "            *[widgets.HBox(row_with_toggles) for row_with_toggles in rows],\n",
    "            widgets.HBox(label_buttons)\n",
    "        ])\n",
    "        return labelling_widget\n",
    "        \n",
    "    def _break_into_rows(self, items_with_desc):\n",
    "        resulting_rows = []\n",
    "        current_line = []\n",
    "        current_length = 0\n",
    "        for item in items_with_desc:\n",
    "            if len(item.description) + current_length > self.LINE_MAX_WIDTH:\n",
    "                resulting_rows.append(current_line)\n",
    "                current_line = []\n",
    "                current_length = 0\n",
    "            current_line.append(item)\n",
    "            current_length += len(item.description)\n",
    "        if len(current_line):\n",
    "            resulting_rows.append(current_line)\n",
    "        return resulting_rows\n",
    "\n",
    "    def _navigate(self, direction, _):\n",
    "        new_index = self.current_index + direction\n",
    "        if 0 < new_index < len(self.docs):\n",
    "            self.current_index = new_index\n",
    "        elif new_index < 0:\n",
    "            self.current_index = len(self.docs) - 1\n",
    "        else:\n",
    "            self.current_index = 0\n",
    "        self.render()\n",
    "    \n",
    "    def render(self):\n",
    "        clear_output()\n",
    "        current_doc = self.docs[self.current_index]\n",
    "        labelling_widget = self._generate_labelling_for(current_doc)\n",
    "        prev_button = widgets.Button(description='← Prev', button_style='primary')\n",
    "        prev_button.on_click(partial(self._navigate, -1))\n",
    "        next_button = widgets.Button(description='Next →', button_style='primary')\n",
    "        next_button.on_click(partial(self._navigate, 1))\n",
    "        control_widgets = widgets.HBox([\n",
    "            prev_button,\n",
    "            next_button,\n",
    "        ])\n",
    "        display(widgets.VBox([\n",
    "            control_widgets,\n",
    "            labelling_widget,\n",
    "        ]))\n",
    "\n",
    "    @property\n",
    "    def results(self):\n",
    "        res = []\n",
    "        for doc, raw_text in zip(self.docs, self.raw_docs):\n",
    "            spanning_labels = []\n",
    "            for token in doc:\n",
    "                if token.label:\n",
    "                    start = token.start\n",
    "                    end = token.end\n",
    "                    \n",
    "                    spanning_labels.append(\n",
    "                        AnnotationResult(label=token.label,\n",
    "                                         span=(start, end),\n",
    "                                         text=raw_text[start:end])\n",
    "                    )\n",
    "            res.append(spanning_labels)\n",
    "        return res\n",
    "                \n",
    "    @staticmethod\n",
    "    def _tokenize(text):\n",
    "        return re.findall(r'\\w+', text)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _create_style_mapping(scheme):\n",
    "        return {label: style for label, style in scheme}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    \"SALT LAKE CITY — Disney will soon finish acquiring 20th Century Fox, which could mean some major changes are in store for the Marvel Cinematic Universe.\",\n",
    "    \"Brazil was one of the final countries that had yet to approve the deal, according to Bloomberg. A source told Bloomberg that Disney was willing to unload the Fox Sports network to different buyers.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheme = [\n",
    "    (\"LOC\", \"info\"),\n",
    "    (\"PER\", \"success\"),\n",
    "    (\"ORG\", \"warning\"),\n",
    "    (\"MISC\", \"success\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b76d5bb4c44415b062c4c682fd7588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(button_style='primary', description='← Prev', style=ButtonStyle()), Butto…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "annotations = Annotator(docs, scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[AnnotationResult(span=(0, 14), text='SALT LAKE CITY', label='LOC'),\n",
       "  AnnotationResult(span=(17, 23), text='Disney', label='ORG'),\n",
       "  AnnotationResult(span=(126, 151), text='Marvel Cinematic Universe', label='MISC')],\n",
       " [AnnotationResult(span=(0, 6), text='Brazil', label='LOC'),\n",
       "  AnnotationResult(span=(85, 94), text='Bloomberg', label='ORG'),\n",
       "  AnnotationResult(span=(110, 119), text='Bloomberg', label='ORG'),\n",
       "  AnnotationResult(span=(125, 131), text='Disney', label='ORG'),\n",
       "  AnnotationResult(span=(158, 168), text='Fox Sports', label='ORG')]]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(text, labels, tokenize_fn=tokenize):\n",
    "    mapping = {label: style for label, style in labels}\n",
    "    def merge(token1, token2):\n",
    "        return Token(\n",
    "            token=token1.token + ' ' + token2.token,\n",
    "            style=token1.style or token2.style,\n",
    "            raw_tokens = token1.raw_tokens + token2.raw_tokens,\n",
    "            label=token1.label or token2.label,\n",
    "            start=min(token1.start,token2.start),\n",
    "            end=max(token1.end, token2.end))\n",
    "\n",
    "    def merge_list(tokens):\n",
    "        while len(tokens) > 1:\n",
    "            tokens = [merge(tokens[0], tokens[1])] + tokens[2:]\n",
    "        return tokens[0]\n",
    "\n",
    "    \n",
    "    original_tokens = tokenize_fn(text)\n",
    "    from_index = 0\n",
    "    merged_tokens = []\n",
    "    for token in original_tokens:\n",
    "        start = text.find(token, from_index)\n",
    "        from_index = start + len(token)\n",
    "        merged_tokens.append(Token(\n",
    "            token=token,\n",
    "            style='',\n",
    "            raw_tokens=[token],\n",
    "            start=start,\n",
    "            end=start + len(token),\n",
    "            label=None\n",
    "        ))\n",
    "    def repaint():\n",
    "        clear_output()\n",
    "        to_display = []\n",
    "\n",
    "        for merged in merged_tokens:\n",
    "            to_display.append(widgets.ToggleButton(\n",
    "                value=False,\n",
    "                description=merged.token,\n",
    "                button_style=merged.style,\n",
    "                disabled=False,\n",
    "                tooltip='Click to select for merging'\n",
    "            ))\n",
    "\n",
    "        def on_label(b):\n",
    "            nonlocal buttons_meta, merged_tokens\n",
    "            new_merged = []\n",
    "            stack = []\n",
    "            new_label = buttons_meta[b]['label']\n",
    "            for token, check in zip(merged_tokens, to_display):\n",
    "                if check.value:\n",
    "                    new_token = token._replace(label=new_label, style=mapping[new_label])\n",
    "                    stack.append(new_token)\n",
    "                else:\n",
    "                    if len(stack):\n",
    "                        new_merged.append(merge_list(stack))\n",
    "                        stack = []\n",
    "                    new_merged.append(token)\n",
    "            if len(stack):\n",
    "                new_merged.append(merge_list(stack))\n",
    "            merged_tokens = new_merged\n",
    "            repaint()\n",
    "        \n",
    "        buttons_meta = {}\n",
    "        label_buttons = []\n",
    "        for label, button_style in labels:\n",
    "            label_button = widgets.Button(description=f'Merge as {label}', button_style=button_style, icon='check')\n",
    "            buttons_meta[label_button] = {'label': label}\n",
    "            label_button.on_click(on_label)\n",
    "            label_buttons.append(label_button)\n",
    "        labelling_widget = widgets.VBox([\n",
    "            widgets.HBox(to_display),\n",
    "            widgets.HBox(label_buttons)\n",
    "        ])\n",
    "        display(labelling_widget)\n",
    "    repaint()\n",
    "    def get_results():\n",
    "        spanning_labels = []\n",
    "        for token in merged_tokens:\n",
    "            if token.label:\n",
    "                start = token.start\n",
    "                end = token.end\n",
    "                spanning_labels.append((token.label, (start, end), text[start:end]))\n",
    "        return spanning_labels\n",
    "    return get_results\n",
    "    \n",
    "get_results = annotate(text = 'this is not a test', labels=[('green', 'success'), ('yellow', 'warning')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
